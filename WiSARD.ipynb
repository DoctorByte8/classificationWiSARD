{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcPhgb6RZhL1"
   },
   "source": [
    "### Atividade de classificação usando redes RAM, pelo modelo WiSARD do aluno **Thiago Ribeiro Aragão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13566,
     "status": "ok",
     "timestamp": 1735402136954,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "LaLzduCOgZyH",
    "outputId": "c3aa02fb-8c4a-43b8-add0-d4b8eaa91c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.12.14)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCcy0h6paptb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Classe WiSARD criada\n",
    "\"\"\"\n",
    "class WiSARD:\n",
    "    def __init__(self, addresSize):\n",
    "        self.addresSize = addresSize\n",
    "        self.discriminador = {}\n",
    "\n",
    "    \"\"\"Mapeamento dos endereços RAMs\"\"\"\n",
    "    def generateAddress(self, inputData):\n",
    "        nBits = inputData.shape[1]\n",
    "        pad = (self.addresSize - (nBits % self.addresSize)) % self.addresSize\n",
    "        paddedData = np.pad(inputData, ((0, 0), (0, pad)), 'constant')\n",
    "        addresses = []\n",
    "        for i in range(0, paddedData.shape[1], self.addresSize):\n",
    "            addresses.append(paddedData[:, i:i + self.addresSize])\n",
    "        return addresses\n",
    "\n",
    "    \"\"\"Treinamento dos discriminadores\"\"\"\n",
    "    def train(self, X, y):\n",
    "        classes = np.unique(y)\n",
    "        self.discriminador = {cls: {} for cls in classes}\n",
    "        for i, label in zip(X, y):\n",
    "            addressses = self.generateAddress(i.reshape(1, -1))\n",
    "            for j in addressses:\n",
    "                addresTuple = tuple(j[0])\n",
    "                if addresTuple not in self.discriminador[label]:\n",
    "                    self.discriminador[label][addresTuple] = 0\n",
    "                self.discriminador[label][addresTuple] += 1\n",
    "\n",
    "    \"\"\"Previsão de qual discriminador indicará a classe\"\"\"\n",
    "    def classify(self, X):\n",
    "        predictions = []\n",
    "        for i in X:\n",
    "            scores = {cls: 0 for cls in self.discriminador.keys()}\n",
    "            addressses = self.generateAddress(i.reshape(1, -1))\n",
    "            for j in addressses:\n",
    "                addresTuple = tuple(j[0])\n",
    "                for classe, memory in self.discriminador.items():\n",
    "                    scores[classe] += memory.get(addresTuple, 0)\n",
    "            predictions.append(max(scores, key=scores.get))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xuEtxuCaLqk"
   },
   "source": [
    "Dataset: nível de obesidade (7 classes de rótulos)\n",
    "---\n",
    "Link: https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1735402163145,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "ThxSfeDJZew3",
    "outputId": "2d1ccd72-4166-43d0-f8e3-e6034b8bb347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 544, 'name': 'Estimation of Obesity Levels Based On Eating Habits and Physical Condition ', 'repository_url': 'https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition', 'data_url': 'https://archive.ics.uci.edu/static/public/544/data.csv', 'abstract': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. ', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Regression', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 2111, 'num_features': 16, 'feature_types': ['Integer'], 'demographics': ['Gender', 'Age'], 'target_col': ['NObeyesdad'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2019, 'last_updated': 'Tue Sep 10 2024', 'dataset_doi': '10.24432/C5H31Z', 'creators': [], 'intro_paper': {'ID': 358, 'type': 'NATIVE', 'title': 'Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico', 'authors': 'Fabio Mendoza Palechor, Alexis De la Hoz Manotas', 'venue': 'Data in Brief', 'year': 2019, 'journal': None, 'DOI': '10.1016/j.dib.2019.104344', 'URL': 'https://www.semanticscholar.org/paper/35b40bacd2ffa9370885b7a3004d88995fd1d011', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Read the article (https://doi.org/10.1016/j.dib.2019.104344) to see the description of the attributes.', 'citation': None}}\n",
      "                              name     role         type demographic  \\\n",
      "0                           Gender  Feature  Categorical      Gender   \n",
      "1                              Age  Feature   Continuous         Age   \n",
      "2                           Height  Feature   Continuous        None   \n",
      "3                           Weight  Feature   Continuous        None   \n",
      "4   family_history_with_overweight  Feature       Binary        None   \n",
      "5                             FAVC  Feature       Binary        None   \n",
      "6                             FCVC  Feature      Integer        None   \n",
      "7                              NCP  Feature   Continuous        None   \n",
      "8                             CAEC  Feature  Categorical        None   \n",
      "9                            SMOKE  Feature       Binary        None   \n",
      "10                            CH2O  Feature   Continuous        None   \n",
      "11                             SCC  Feature       Binary        None   \n",
      "12                             FAF  Feature   Continuous        None   \n",
      "13                             TUE  Feature      Integer        None   \n",
      "14                            CALC  Feature  Categorical        None   \n",
      "15                          MTRANS  Feature  Categorical        None   \n",
      "16                      NObeyesdad   Target  Categorical        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                None  None             no  \n",
      "1                                                None  None             no  \n",
      "2                                                None  None             no  \n",
      "3                                                None  None             no  \n",
      "4   Has a family member suffered or suffers from o...  None             no  \n",
      "5            Do you eat high caloric food frequently?  None             no  \n",
      "6        Do you usually eat vegetables in your meals?  None             no  \n",
      "7              How many main meals do you have daily?  None             no  \n",
      "8                  Do you eat any food between meals?  None             no  \n",
      "9                                       Do you smoke?  None             no  \n",
      "10                 How much water do you drink daily?  None             no  \n",
      "11         Do you monitor the calories you eat daily?  None             no  \n",
      "12           How often do you have physical activity?  None             no  \n",
      "13  How much time do you use technological devices...  None             no  \n",
      "14                    How often do you drink alcohol?  None             no  \n",
      "15           Which transportation do you usually use?  None             no  \n",
      "16                                      Obesity level  None             no  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Código copiado da página do UCI para import do dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition = fetch_ucirepo(id=544)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.features\n",
    "y = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.targets\n",
    "\n",
    "# metadata\n",
    "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.metadata)\n",
    "\n",
    "# variable information\n",
    "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1735402167464,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "FmcY80TKgn1-",
    "outputId": "f694388f-1856-4b0e-da75-e4ced6d8503b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 14.000000000000002%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Binarização dos dados e correção de inconsistências.\"\"\"\n",
    "def binarize(data):\n",
    "    \"\"\"Checar missing values\"\"\"\n",
    "    if hasattr(data, 'values'):\n",
    "        data = data.values\n",
    "\n",
    "    \"\"\"Identificar quais colunas são contínuas\"\"\"\n",
    "    continuousFeatures = np.ptp(data, axis=0) > 1\n",
    "    binarizedData = []\n",
    "\n",
    "    for i, ehContinuous in enumerate(continuousFeatures):\n",
    "        column = data[:, i]\n",
    "        if ehContinuous:\n",
    "            normalizedFeat = (column - column.min()) / (column.max() - column.min() + 1e-8)\n",
    "            binarizedFeat = np.unpackbits((normalizedFeat * 255).astype(np.uint8)).reshape(-1, 8)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "        else:\n",
    "            binarizedFeat = column.astype(np.uint8).reshape(-1, 1)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "\n",
    "    \"\"\"Combina todas as colunas binarizadas e empilha horizontalmente\"\"\"\n",
    "    binarizedData = np.hstack(binarizedData)\n",
    "    return binarizedData\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Estas etapas de pré-processamento dos dados e divisão do dataset em treino e teste foram ajustadas.\"\"\"\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = LabelEncoder().fit_transform(np.array(y).ravel())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino = scaler.fit_transform(X_treino)\n",
    "X_teste = scaler.transform(X_teste)\n",
    "\n",
    "\"\"\"Conjuntos teste e treino agora 'binarizados'\"\"\"\n",
    "X_treino_bin = binarize(X_treino)\n",
    "X_teste_bin = binarize(X_teste)\n",
    "\n",
    "\"\"\"Treino\"\"\"\n",
    "addressize = max(4, min(8, int(np.log2(X_treino_bin.shape[1]))))\n",
    "model = WiSARD(addressize)\n",
    "model.train(X_treino_bin, y_treino)\n",
    "\n",
    "\"\"\"Previsão\"\"\"\n",
    "yPrevisto = model.classify(X_teste_bin)\n",
    "\n",
    "\"\"\"Hora da verdade\"\"\"\n",
    "accuracy = accuracy_score(y_teste, yPrevisto)\n",
    "print(\"Acurácia: \" + str(round(accuracy, 2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XYOj5jEaMrb"
   },
   "source": [
    "Dataset: avaliação de carro (4 classes de rótulos)\n",
    "---\n",
    "Link: https://archive.ics.uci.edu/dataset/19/car+evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1735402172103,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "5-MN1jAbaU6k",
    "outputId": "5d45fffa-116f-46ee-b9ef-95193fe9b08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'ID': 249, 'type': 'NATIVE', 'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkovič', 'venue': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Código copiado da página do UCI para import do dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets\n",
    "\n",
    "# metadata\n",
    "print(car_evaluation.metadata)\n",
    "\n",
    "# variable information\n",
    "print(car_evaluation.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1735402175177,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "prl05vbEnea7",
    "outputId": "0eb15b91-9f21-40c9-d975-170353815a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 71.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Binarização dos dados e correção de inconsistências.\"\"\"\n",
    "def binarize(data):\n",
    "    \"\"\"Checar missing values\"\"\"\n",
    "    if hasattr(data, 'values'):\n",
    "        data = data.values\n",
    "\n",
    "    \"\"\"Identificar quais colunas são contínuas\"\"\"\n",
    "    continuousFeatures = np.ptp(data, axis=0) > 1\n",
    "    binarizedData = []\n",
    "\n",
    "    for i, ehContinuous in enumerate(continuousFeatures):\n",
    "        column = data[:, i]\n",
    "        if ehContinuous:\n",
    "            normalizedFeat = (column - column.min()) / (column.max() - column.min() + 1e-8)\n",
    "            binarizedFeat = np.unpackbits((normalizedFeat * 255).astype(np.uint8)).reshape(-1, 8)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "        else:\n",
    "            binarizedFeat = column.astype(np.uint8).reshape(-1, 1)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "\n",
    "    \"\"\"Combina todas as colunas binarizadas e empilha horizontalmente\"\"\"\n",
    "    binarizedData = np.hstack(binarizedData)\n",
    "    return binarizedData\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Estas etapas de pré-processamento dos dados e divisão do dataset em treino e teste foram ajustadas.\"\"\"\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = LabelEncoder().fit_transform(np.array(y).ravel())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino = scaler.fit_transform(X_treino)\n",
    "X_teste = scaler.transform(X_teste)\n",
    "\n",
    "\"\"\"Conjuntos teste e treino agora 'binarizados'\"\"\"\n",
    "X_treino_bin = binarize(X_treino)\n",
    "X_teste_bin = binarize(X_teste)\n",
    "\n",
    "\"\"\"Treino\"\"\"\n",
    "addressize = max(4, min(8, int(np.log2(X_treino_bin.shape[1]))))\n",
    "model = WiSARD(addressize)\n",
    "model.train(X_treino_bin, y_treino)\n",
    "\n",
    "\"\"\"Previsão\"\"\"\n",
    "yPrevisto = model.classify(X_teste_bin)\n",
    "\n",
    "\"\"\"Hora da verdade\"\"\"\n",
    "accuracy = accuracy_score(y_teste, yPrevisto)\n",
    "print(\"Acurácia: \" + str(round(accuracy, 2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4WDpcsvaVKr"
   },
   "source": [
    "Dataset: tamanhos de lentes de grau para pacientes (3 classes de rótulos)\n",
    "---\n",
    "Link: https://archive.ics.uci.edu/dataset/58/lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1735402179003,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "GK6c3HwiaVSE",
    "outputId": "d2c46c99-d2db-4617-ad92-c4072bc028b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 58, 'name': 'Lenses', 'repository_url': 'https://archive.ics.uci.edu/dataset/58/lenses', 'data_url': 'https://archive.ics.uci.edu/static/public/58/data.csv', 'abstract': 'Database for fitting contact lenses', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 24, 'num_features': 3, 'feature_types': ['Categorical'], 'demographics': ['Age'], 'target_col': ['class'], 'index_col': ['id'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1987, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5K88Z', 'creators': ['J. Cendrowska'], 'intro_paper': None, 'additional_info': {'summary': 'The examples are complete and noise free. The examples highly simplified the problem. The attributes do not fully describe all the factors affecting the decision as to which type, if any, to fit.\\r\\n\\r\\n Notes:  \\r\\n\\r\\n--This database is complete (all possible combinations of attribute-value pairs are represented).\\r\\n\\r\\n--Each instance is complete and correct.\\r\\n\\r\\n--9 rules cover the training set.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '    1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\\n    2. spectacle prescription:  (1) myope, (2) hypermetrope\\n    3. astigmatic:     (1) no, (2) yes\\n    4. tear production rate:  (1) reduced, (2) normal', 'citation': None}}\n",
      "                     name     role         type demographic description units  \\\n",
      "0                      id       ID      Integer        None        None  None   \n",
      "1                     age  Feature  Categorical         Age        None  None   \n",
      "2  spectacle_prescription  Feature  Categorical        None        None  None   \n",
      "3              astigmatic  Feature       Binary        None        None  None   \n",
      "4                   class   Target  Categorical        None        None  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3             no  \n",
      "4             no  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Código copiado da página do UCI para import do dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "lenses = fetch_ucirepo(id=58)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = lenses.data.features\n",
    "y = lenses.data.targets\n",
    "\n",
    "# metadata\n",
    "print(lenses.metadata)\n",
    "\n",
    "# variable information\n",
    "print(lenses.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1735402180973,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "2N8nK9KcpGrb",
    "outputId": "5268b2cb-f88a-4e65-cc15-e58cad527b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 59.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Binarização dos dados e correção de inconsistências.\"\"\"\n",
    "def binarize(data):\n",
    "    \"\"\"Checar missing values\"\"\"\n",
    "    if hasattr(data, 'values'):\n",
    "        data = data.values\n",
    "\n",
    "    \"\"\"Identificar quais colunas são contínuas\"\"\"\n",
    "    continuousFeatures = np.ptp(data, axis=0) > 1\n",
    "    binarizedData = []\n",
    "\n",
    "    for i, ehContinuous in enumerate(continuousFeatures):\n",
    "        column = data[:, i]\n",
    "        if ehContinuous:\n",
    "            normalizedFeat = (column - column.min()) / (column.max() - column.min() + 1e-8)\n",
    "            binarizedFeat = np.unpackbits((normalizedFeat * 255).astype(np.uint8)).reshape(-1, 8)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "        else:\n",
    "            binarizedFeat = column.astype(np.uint8).reshape(-1, 1)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "\n",
    "    \"\"\"Combina todas as colunas binarizadas e empilha horizontalmente\"\"\"\n",
    "    binarizedData = np.hstack(binarizedData)\n",
    "    return binarizedData\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Estas etapas de pré-processamento dos dados e divisão do dataset em treino e teste foram ajustadas.\"\"\"\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = LabelEncoder().fit_transform(np.array(y).ravel())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino = scaler.fit_transform(X_treino)\n",
    "X_teste = scaler.transform(X_teste)\n",
    "\n",
    "\"\"\"Conjuntos teste e treino agora 'binarizados'\"\"\"\n",
    "X_treino_bin = binarize(X_treino)\n",
    "X_teste_bin = binarize(X_teste)\n",
    "\n",
    "\"\"\"Treino\"\"\"\n",
    "addressize = max(4, min(8, int(np.log2(X_treino_bin.shape[1]))))\n",
    "model = WiSARD(addressize)\n",
    "model.train(X_treino_bin, y_treino)\n",
    "\n",
    "\"\"\"Previsão\"\"\"\n",
    "yPrevisto = model.classify(X_teste_bin)\n",
    "\n",
    "\"\"\"Hora da verdade\"\"\"\n",
    "accuracy = accuracy_score(y_teste, yPrevisto)\n",
    "print(\"Acurácia: \" + str(round(accuracy, 2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbULVw5jfxKl"
   },
   "source": [
    "Dataset: Predict Students' Dropout and Academic Success\n",
    "---\n",
    "Link: https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1735402185407,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "9M4bqbqufxKl",
    "outputId": "aa5d5612-c152-438d-8ab2-563eb8ec2109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 697, 'name': \"Predict Students' Dropout and Academic Success\", 'repository_url': 'https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success', 'data_url': 'https://archive.ics.uci.edu/static/public/697/data.csv', 'abstract': \"A dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies.\\nThe dataset includes information known at the time of student enrollment (academic path, demographics, and social-economic factors) and the students' academic performance at the end of the first and second semesters. \\nThe data is used to build classification models to predict students' dropout and academic sucess. The problem is formulated as a three category classification task, in which there is a strong imbalance towards one of the classes.\", 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 4424, 'num_features': 36, 'feature_types': ['Real', 'Categorical', 'Integer'], 'demographics': ['Marital Status', 'Education Level', 'Nationality', 'Occupation', 'Gender', 'Age'], 'target_col': ['Target'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2021, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5MC89', 'creators': ['Valentim Realinho', 'Mónica Vieira Martins', 'Jorge Machado', 'Luís Baptista'], 'intro_paper': {'ID': 99, 'type': 'NATIVE', 'title': \"Early prediction of student's performance in higher education: a case study\", 'authors': 'Mónica V. Martins, Daniel Tolledo, Jorge Machado, Luís M. T. Baptista, and Valentim Realinho', 'venue': 'Trends and Applications in Information Systems and Technologies', 'year': 2021, 'journal': 'Advances in Intelligent Systems and Computing series', 'DOI': 'http://www.doi.org/10.1007/978-3-030-72657-7_16', 'URL': 'http://www.worldcist.org/2021/', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': None, 'purpose': 'The dataset was created in a project that aims to contribute to the reduction of academic dropout and failure in higher education, by using machine learning techniques to identify students at risk at an early stage of their academic path, so that strategies to support them can be put into place. \\n\\nThe dataset includes information known at the time of student enrollment – academic path, demographics, and social-economic factors. \\n\\nThe problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course. \\n', 'funded_by': 'This dataset is supported by program SATDAP - Capacitação da Administração Pública under grant POCI-05-5762-FSE-000191, Portugal.', 'instances_represent': 'Each instance is a student', 'recommended_data_splits': 'The dataset was used, in our project, with a data split of 80% for training and 20% for test.', 'sensitive_data': None, 'preprocessing_description': 'We performed a rigorous data preprocessing to handle data from anomalies, unexplainable outliers, and missing values.', 'variable_info': None, 'citation': 'If you use this dataset in experiments for a scientific publication, please kindly cite our paper: \\nM.V.Martins, D. Tolledo, J. Machado, L. M.T. Baptista, V.Realinho. (2021) \"Early prediction of student’s performance in higher education: a case study\" Trends and Applications in Information Systems and Technologies, vol.1, in Advances in Intelligent Systems and Computing series. Springer. DOI: 10.1007/978-3-030-72657-7_16'}}\n",
      "                                              name     role         type  \\\n",
      "0                                   Marital Status  Feature      Integer   \n",
      "1                                 Application mode  Feature      Integer   \n",
      "2                                Application order  Feature      Integer   \n",
      "3                                           Course  Feature      Integer   \n",
      "4                       Daytime/evening attendance  Feature      Integer   \n",
      "5                           Previous qualification  Feature      Integer   \n",
      "6                   Previous qualification (grade)  Feature   Continuous   \n",
      "7                                      Nacionality  Feature      Integer   \n",
      "8                           Mother's qualification  Feature      Integer   \n",
      "9                           Father's qualification  Feature      Integer   \n",
      "10                             Mother's occupation  Feature      Integer   \n",
      "11                             Father's occupation  Feature      Integer   \n",
      "12                                 Admission grade  Feature   Continuous   \n",
      "13                                       Displaced  Feature      Integer   \n",
      "14                       Educational special needs  Feature      Integer   \n",
      "15                                          Debtor  Feature      Integer   \n",
      "16                         Tuition fees up to date  Feature      Integer   \n",
      "17                                          Gender  Feature      Integer   \n",
      "18                              Scholarship holder  Feature      Integer   \n",
      "19                               Age at enrollment  Feature      Integer   \n",
      "20                                   International  Feature      Integer   \n",
      "21             Curricular units 1st sem (credited)  Feature      Integer   \n",
      "22             Curricular units 1st sem (enrolled)  Feature      Integer   \n",
      "23          Curricular units 1st sem (evaluations)  Feature      Integer   \n",
      "24             Curricular units 1st sem (approved)  Feature      Integer   \n",
      "25                Curricular units 1st sem (grade)  Feature      Integer   \n",
      "26  Curricular units 1st sem (without evaluations)  Feature      Integer   \n",
      "27             Curricular units 2nd sem (credited)  Feature      Integer   \n",
      "28             Curricular units 2nd sem (enrolled)  Feature      Integer   \n",
      "29          Curricular units 2nd sem (evaluations)  Feature      Integer   \n",
      "30             Curricular units 2nd sem (approved)  Feature      Integer   \n",
      "31                Curricular units 2nd sem (grade)  Feature      Integer   \n",
      "32  Curricular units 2nd sem (without evaluations)  Feature      Integer   \n",
      "33                               Unemployment rate  Feature   Continuous   \n",
      "34                                  Inflation rate  Feature   Continuous   \n",
      "35                                             GDP  Feature   Continuous   \n",
      "36                                          Target   Target  Categorical   \n",
      "\n",
      "        demographic                                        description units  \\\n",
      "0    Marital Status  1 – single 2 – married 3 – widower 4 – divorce...  None   \n",
      "1              None  1 - 1st phase - general contingent 2 - Ordinan...  None   \n",
      "2              None  Application order (between 0 - first choice; a...  None   \n",
      "3              None  33 - Biofuel Production Technologies 171 - Ani...  None   \n",
      "4              None                            1 – daytime 0 - evening  None   \n",
      "5   Education Level  1 - Secondary education 2 - Higher education -...  None   \n",
      "6              None  Grade of previous qualification (between 0 and...  None   \n",
      "7       Nationality  1 - Portuguese; 2 - German; 6 - Spanish; 11 - ...  None   \n",
      "8   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
      "9   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
      "10       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
      "11       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
      "12             None                Admission grade (between 0 and 200)  None   \n",
      "13             None                                     1 – yes 0 – no  None   \n",
      "14             None                                     1 – yes 0 – no  None   \n",
      "15             None                                     1 – yes 0 – no  None   \n",
      "16             None                                     1 – yes 0 – no  None   \n",
      "17           Gender                                1 – male 0 – female  None   \n",
      "18             None                                     1 – yes 0 – no  None   \n",
      "19              Age                       Age of studend at enrollment  None   \n",
      "20             None                                     1 – yes 0 – no  None   \n",
      "21             None  Number of curricular units credited in the 1st...  None   \n",
      "22             None  Number of curricular units enrolled in the 1st...  None   \n",
      "23             None  Number of evaluations to curricular units in t...  None   \n",
      "24             None  Number of curricular units approved in the 1st...  None   \n",
      "25             None  Grade average in the 1st semester (between 0 a...  None   \n",
      "26             None  Number of curricular units without evalutions ...  None   \n",
      "27             None  Number of curricular units credited in the 2nd...  None   \n",
      "28             None  Number of curricular units enrolled in the 2nd...  None   \n",
      "29             None  Number of evaluations to curricular units in t...  None   \n",
      "30             None  Number of curricular units approved in the 2nd...  None   \n",
      "31             None  Grade average in the 2nd semester (between 0 a...  None   \n",
      "32             None  Number of curricular units without evalutions ...  None   \n",
      "33             None                              Unemployment rate (%)  None   \n",
      "34             None                                 Inflation rate (%)  None   \n",
      "35             None                                                GDP  None   \n",
      "36             None  Target. The problem is formulated as a three c...  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n",
      "32             no  \n",
      "33             no  \n",
      "34             no  \n",
      "35             no  \n",
      "36             no  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Código copiado da página do UCI para import do dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "predict_students_dropout_and_academic_success = fetch_ucirepo(id=697)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = predict_students_dropout_and_academic_success.data.features\n",
    "y = predict_students_dropout_and_academic_success.data.targets\n",
    "\n",
    "# metadata\n",
    "print(predict_students_dropout_and_academic_success.metadata)\n",
    "\n",
    "# variable information\n",
    "print(predict_students_dropout_and_academic_success.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1934,
     "status": "ok",
     "timestamp": 1735402193207,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "mv4d4pclfxKl",
    "outputId": "06c03d4f-ec78-4a06-f857-a1f274f6958a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 49.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Binarização dos dados e correção de inconsistências.\"\"\"\n",
    "def binarize(data):\n",
    "    \"\"\"Checar missing values\"\"\"\n",
    "    if hasattr(data, 'values'):\n",
    "        data = data.values\n",
    "\n",
    "    \"\"\"Identificar quais colunas são contínuas\"\"\"\n",
    "    continuousFeatures = np.ptp(data, axis=0) > 1\n",
    "    binarizedData = []\n",
    "\n",
    "    for i, ehContinuous in enumerate(continuousFeatures):\n",
    "        column = data[:, i]\n",
    "        if ehContinuous:\n",
    "            normalizedFeat = (column - column.min()) / (column.max() - column.min() + 1e-8)\n",
    "            binarizedFeat = np.unpackbits((normalizedFeat * 255).astype(np.uint8)).reshape(-1, 8)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "        else:\n",
    "            binarizedFeat = column.astype(np.uint8).reshape(-1, 1)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "\n",
    "    \"\"\"Combina todas as colunas binarizadas e empilha horizontalmente\"\"\"\n",
    "    binarizedData = np.hstack(binarizedData)\n",
    "    return binarizedData\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Estas etapas de pré-processamento dos dados e divisão do dataset em treino e teste foram ajustadas.\"\"\"\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = LabelEncoder().fit_transform(np.array(y).ravel())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino = scaler.fit_transform(X_treino)\n",
    "X_teste = scaler.transform(X_teste)\n",
    "\n",
    "\"\"\"Conjuntos teste e treino agora 'binarizados'\"\"\"\n",
    "X_treino_bin = binarize(X_treino)\n",
    "X_teste_bin = binarize(X_teste)\n",
    "\n",
    "\"\"\"Treino\"\"\"\n",
    "addressize = max(4, min(8, int(np.log2(X_treino_bin.shape[1]))))\n",
    "model = WiSARD(addressize)\n",
    "model.train(X_treino_bin, y_treino)\n",
    "\n",
    "\"\"\"Previsão\"\"\"\n",
    "yPrevisto = model.classify(X_teste_bin)\n",
    "\n",
    "\"\"\"Hora da verdade\"\"\"\n",
    "accuracy = accuracy_score(y_teste, yPrevisto)\n",
    "print(\"Acurácia: \" + str(round(accuracy, 2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl9jBIecfytC"
   },
   "source": [
    "Dataset: Zoo\n",
    "---\n",
    "Link: https://archive.ics.uci.edu/dataset/111/zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1735402196626,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "1sieIlyNfytD",
    "outputId": "d4f0f693-38ac-4c7f-aad9-4a2350c9de06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 111, 'name': 'Zoo', 'repository_url': 'https://archive.ics.uci.edu/dataset/111/zoo', 'data_url': 'https://archive.ics.uci.edu/static/public/111/data.csv', 'abstract': 'Artificial, 7 classes of animals', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 101, 'num_features': 16, 'feature_types': ['Categorical', 'Integer'], 'demographics': [], 'target_col': ['type'], 'index_col': ['animal_name'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1990, 'last_updated': 'Fri Sep 15 2023', 'dataset_doi': '10.24432/C5R59V', 'creators': ['Richard Forsyth'], 'intro_paper': None, 'additional_info': {'summary': 'A simple database containing 17 Boolean-valued attributes.  The \"type\" attribute appears to be the class attribute.  Here is a breakdown of which animals are in which type: (I find it unusual that there are 2 instances of \"frog\" and one of \"girl\"!)', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '   1. animal name:      Unique for each instance\\r\\n   2. hair:\\t\\tBoolean\\r\\n   3. feathers:\\t\\tBoolean\\r\\n   4. eggs:\\t\\tBoolean\\r\\n   5. milk:\\t\\tBoolean\\r\\n   6. airborne:\\t\\tBoolean\\r\\n   7. aquatic:\\t\\tBoolean\\r\\n   8. predator:\\t\\tBoolean\\r\\n   9. toothed:\\t\\tBoolean\\r\\n  10. backbone:\\t\\tBoolean\\r\\n  11. breathes:\\t\\tBoolean\\r\\n  12. venomous:\\t\\tBoolean\\r\\n  13. fins:\\t\\tBoolean\\r\\n  14. legs:\\t\\tNumeric (set of values: {0,2,4,5,6,8})\\r\\n  15. tail:\\t\\tBoolean\\r\\n  16. domestic:\\t\\tBoolean\\r\\n  17. catsize:\\t\\tBoolean\\r\\n  18. type:\\t\\tNumeric (integer values in range [1,7])', 'citation': None}}\n",
      "           name     role         type demographic description units  \\\n",
      "0   animal_name       ID  Categorical        None        None  None   \n",
      "1          hair  Feature       Binary        None        None  None   \n",
      "2      feathers  Feature       Binary        None        None  None   \n",
      "3          eggs  Feature       Binary        None        None  None   \n",
      "4          milk  Feature       Binary        None        None  None   \n",
      "5      airborne  Feature       Binary        None        None  None   \n",
      "6       aquatic  Feature       Binary        None        None  None   \n",
      "7      predator  Feature       Binary        None        None  None   \n",
      "8       toothed  Feature       Binary        None        None  None   \n",
      "9      backbone  Feature       Binary        None        None  None   \n",
      "10     breathes  Feature       Binary        None        None  None   \n",
      "11     venomous  Feature       Binary        None        None  None   \n",
      "12         fins  Feature       Binary        None        None  None   \n",
      "13         legs  Feature  Categorical        None        None  None   \n",
      "14         tail  Feature       Binary        None        None  None   \n",
      "15     domestic  Feature       Binary        None        None  None   \n",
      "16      catsize  Feature       Binary        None        None  None   \n",
      "17         type   Target  Categorical        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Código copiado da página do UCI para import do dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "zoo = fetch_ucirepo(id=111)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = zoo.data.features\n",
    "y = zoo.data.targets\n",
    "\n",
    "# metadata\n",
    "print(zoo.metadata)\n",
    "\n",
    "# variable information\n",
    "print(zoo.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1735402203045,
     "user": {
      "displayName": "Thiago Ribeiro Aragao",
      "userId": "07459982461555014807"
     },
     "user_tz": 180
    },
    "id": "D-TKonnWfytD",
    "outputId": "6bd258a3-f851-4e5c-941f-8bd5da47cec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 13.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Binarização dos dados e correção de inconsistências.\"\"\"\n",
    "def binarize(data):\n",
    "    \"\"\"Checar missing values\"\"\"\n",
    "    if hasattr(data, 'values'):\n",
    "        data = data.values\n",
    "\n",
    "    \"\"\"Identificar quais colunas são contínuas\"\"\"\n",
    "    continuousFeatures = np.ptp(data, axis=0) > 1\n",
    "    binarizedData = []\n",
    "\n",
    "    for i, ehContinuous in enumerate(continuousFeatures):\n",
    "        column = data[:, i]\n",
    "        if ehContinuous:\n",
    "            normalizedFeat = (column - column.min()) / (column.max() - column.min() + 1e-8)\n",
    "            binarizedFeat = np.unpackbits((normalizedFeat * 255).astype(np.uint8)).reshape(-1, 8)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "        else:\n",
    "            binarizedFeat = column.astype(np.uint8).reshape(-1, 1)\n",
    "            binarizedData.append(binarizedFeat)\n",
    "\n",
    "    \"\"\"Combina todas as colunas binarizadas e empilha horizontalmente\"\"\"\n",
    "    binarizedData = np.hstack(binarizedData)\n",
    "    return binarizedData\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Estas etapas de pré-processamento dos dados e divisão do dataset em treino e teste foram ajustadas.\"\"\"\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = LabelEncoder().fit_transform(np.array(y).ravel())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino = scaler.fit_transform(X_treino)\n",
    "X_teste = scaler.transform(X_teste)\n",
    "\n",
    "\"\"\"Conjuntos teste e treino agora 'binarizados'\"\"\"\n",
    "X_treino_bin = binarize(X_treino)\n",
    "X_teste_bin = binarize(X_teste)\n",
    "\n",
    "\"\"\"Treino\"\"\"\n",
    "addressize = max(4, min(8, int(np.log2(X_treino_bin.shape[1]))))\n",
    "model = WiSARD(addressize)\n",
    "model.train(X_treino_bin, y_treino)\n",
    "\n",
    "\"\"\"Previsão\"\"\"\n",
    "yPrevisto = model.classify(X_teste_bin)\n",
    "\n",
    "\"\"\"Hora da verdade\"\"\"\n",
    "accuracy = accuracy_score(y_teste, yPrevisto)\n",
    "print(\"Acurácia: \" + str(round(accuracy, 2)*100) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMrQ0fiqNRWJERNN+SOpoUM",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
